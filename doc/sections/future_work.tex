% !TeX root = ../main.tex

% \Section{Further Work}

Similarly to Section \ref{sec:prob_obs_ss}, I will fit three different classes of hidden Markov models to both real-world and simulated data sets:

\begin{enumerate}
    \item Traditional HMMs without labels,
    \item PHMMs which model labels as fixed (see Equation (\ref{eqn:PHMM_emis_niave})).
    \item PHMMs which incorporate labels into the model's emission distributions (see Equation (\ref{eqn:PHMM_emis})).
\end{enumerate}

%\subsection{Simulation Study}

I will conduct a simulation study to understand how the parameter estimate error, hidden-state decoding accuracy, and the optimal value of $\lambda$ (i.e. the weighting of labelled vs unlabelled data) depends upon the model structure and degree of model misspecification. I will extend the motivating example from Section \ref{sec:prob_obs_ss} by simulating data from a variety of models with different sequence lengths ($T$), numbers of hidden states ($N$), and label observation probabilities $\left(f^{(i)}(x_t\ell_t|y_t)\right)$. I will also adjust the parameters and structure of the generating PHMM to match the HMM that was estimated in the results section of chapter 2. I will introduce model misspecification by simulating data from HMMs with more hidden states and/or heavily-tailed emission distributions compared to the model used for inference. Finally, I will use many different likelihood weighting terms ($\lambda$) to fit each misspecified model.

I will use several metrics to evaluate each model's performance. In addition to reporting the bias of each parameter estimate, I will estimate several distances between the estimated HMMs and the generating HMM, including the Wasserstein metric \citep{Chen:2020} and the KL divergence \citep{Kullback:1951}. I will report the average decoding accuracy for each model, and plot sequences of simulated data along with the hidden states estimated by each model. This is similar to the simulation study from chapter 2.

%\subsection{Case Study}

Finally, I will fit a variety of PHMMs to the kinematic data of killer whales off the coast of British Columbia. This case study will asses whether semi-supervised HMMs can produce better-fitting and more realistic models for real-world movement data. I will vary the number of hidden states $N$ and the likelihood weighting parameter $\lambda$ to create several candidate models. I then will fit all of these candidate models to the sparsely labelled killer whale kinematic data set introduced in Section \ref{sec:w_like_ss}. 

To quantitatively evaluate each candidate model, I will using k-fold cross-validation with two different loss functions: (1) The likelihood of each validation set \citep{Celeux:2008}, and (2) the estimated probability that each labelled hidden state is equal to its true (held-out) label. To qualitatively evaluate each model, I will report pseudoresiduals, empirical histograms, and the estimated hidden states of selected dives from the case study. This is similar to the case study from chapter 2. %Because each model may capture different biological phenomena, I will also report parameter estimates and decoded hidden state sequences from several candidate models.


%%%

\iffalse
a PHMM as defined above and fit both a regular PHMM as well as a PHMM that explicitly models the probability of observing a label. Then, I will comparing the resulting models to determine the effect of assuming that $p^{(i)}(y^o_t)$ is a constant. While the precise simulation study setup is subject to change, I will beginning with the following setup:

\begin{enumerate}
    \item Simulate 500 data sets from a PHMM with Normal emissions and $p^{(i)}$
\end{enumerate}

Then, I will compare the errors of the estimated probability distributions, the transition matrices, and the standard errors. One metric is the proportion of hidden states in the simulation study which are correctly estimated as a function of the number of labels observed. Another is the Wasserstein distance between a given model and the generating model in a simulation study. The relationship between HMM accuracy and the number of labelled examples may change depending upon the number of possible hidden states (N) the number of observations (T), the structure of the PHMM, etc.

\subsection{weighted likelihood}

I will 

\fi
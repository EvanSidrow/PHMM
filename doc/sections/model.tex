%\section{Model formulation}

We begin by introducing new notation to describe labels as observations within an HMM. If labels are modelled as observations, then it is straightforward to model how observing a label at time $t$ can depend upon both the hidden state $X_t$ and the observation $Y_t$.

Suppose that an observation $Y_t$ can be decomposed into an underlying observation $Z_t$ as well as a \textit{label} $L_t \in \{\emptyset,1,\ldots,N\}$ such that $Y_t = \{Z_t,L_t\}$. We denote a realization of $Y_t$ as $y_t = \{z_t,\ell_t\}$.
%
%\begin{equation*}
%    L_t := \begin{cases} X_t, & X_t\text{ is observed} \\ \emptyset, & \text{otherwise} \end{cases}.
%\end{equation*}
%
%The label $L_t$ is itself an observation from the HMM, just like $Y_t$. As such, we define the \textit{augmented} observation at time $t$ as
%
%\begin{equation*}
%    \Ya_t := (Y_t, L_t), \qquad
%    \ya_t := (y_t, \ell_t),
%\end{equation*}
%
%where $\Ya_t$ is a random variable and $\ya_t$ is a realization of that random variable. In this way, one may simply specify an HMM so that the hidden states are $X = \{X_1,\ldots,X_T\}$ and the observations are $\Ya = \{\Ya_1,\ldots,\Ya_T\}$. An HMM defined in this way obeys the standard assumption that the set of observations $\{\Ya_1,\ldots,\Ya_T\}$ are independent from one another after conditioning on $X$.
%
% introduce \thetaa here (augemented theta) %
%
We can define the emission distribution $f$ to explicitly model the probability of observing a label $L_t$ conditioned on the hidden state $X_t$ and the observation $Z_t$. First, we decompose the HMM parameters for hidden state $i$ as $\theta^{(i)} := \{\theta^{(i)}_{Z},\theta_{L}^{(i)}\}$. Then, we denote the probability density of $Z_t$ at $z_t$ given $X_t = i$ as $f_{z}^{(i)}(z_t ~;~ \theta_{z}^{(i)})$, and we denote the probability mass of $L_t$ at $\ell_t$ given $X_t = i$ and $Z_t = z_t$ as $f_{\ell}^{(i)}(\ell_t \mid z_t ~;~ \theta^{(i)}_{\ell})$. The full density of $Y_t$ given $X_t = i$ is thus
%
\begin{gather}
    f^{(i)}(y_t ~;~ \theta^{(i)}) = f_{z}^{(i)}(z_t ~;~ \theta_{z}^{(i)}) ~ f_{\ell}^{(i)}(\ell_t \mid z_t ~;~ \theta^{(i)}_{\ell})
    \label{eqn:PHMM_emis}
\end{gather}
%
We refer to this model as a \textit{partially hidden Markov model}, or PHMM. The PHMM is a specific instance of an HMM, so its likelihood is identical to a standard HMM.

\subsection{Types of PHMMs}

\subsubsection{Fixed labels}

Previous studies \citep{McClintock:2018,Li:2021} incorporate labels into HMMs using an approach that is equivalent to a specific instance of the PHMM. In particular, define some non-random set of observation times as $\calT$. Then, the studies above implicitly use a time-varying probability mass for $L_t$ which we denote as $f_{\ell,t}^{(i)}(\ell_t)$, where
%
\begin{gather}
    f_{\ell,t}^{(i)}(\ell_t) = \begin{cases} 1, & t \in \calT, \enspace \ell_t = i, \\ 
    %
    1, & t \notin \calT, \enspace \ell_t = \emptyset, \\ 
    %
    0, & \text{otherwise}. \end{cases} \label{eqn:PHMM_emis_niave}
\end{gather}
%
In words, these studies assume that the probability of observing a label is either $1$ or $0$, and these probabilities are predefined by some known set $\calT$.

\subsubsection{Random labels}

However, in many situations the act of observing a label itself may be a random event that depends upon either the observation $Z_t$ or the hidden state $X_t$. As an example to motivate the inclusion of random labels, consider an HMM used to model the behaviour of a predator. Assume that there are two behavioural states (resting and hunting), where $X_t = 1$ corresponds to resting and $X_t = 2$ corresponds to hunting. Further, suppose that researchers can observe successful prey captures via a crunching sound that is registered on an acoustic recorder when the animal is hunting. Given that the predator is hunting, denote the probability of observing a crunching sound on the acoustic recorder as $p$. Labels are never observed when the animal is resting ($X_t = 1$), so $f^{(1)}(\ell_t = \emptyset \mid z_t) = 1$ for all observations $z_t$. However, a label is observed with probability $p$ if the animal is hunting ($X_t = 2$), so $f^{(2)}(\ell_t = 2 \mid z_t) = p$ and $f^{(2)}(\ell_t = \emptyset \mid z_t) = 1-p$. In this way, the existence of a label itself may provide information that can be included within a PHMM to improve parameter estimates.

In addition, it is reasonable to assume that the predator may be more likely to catch its prey when it is running faster, so $f^{(2)}(\ell_t = 2 \mid z_t)$ may be modelled as an increasing function of $z_t$. %(say, $f^{(2)}(\ell_t = \emptyset \mid z_t) = 1-\text{expit}(z_t)$). 
In this way, the probability of observing a label depends upon both the hidden behavioural state $X_t$ and the underlying observation $Z_t$.

Further, suppose that, while an animal is resting, it bumps into a rock with a sound identical to a crunch of prey with probability $q$. In this case, there is a nonzero probability of mislabelling a resting state as foraging, so $f^{(1)}(\ell_t = 2 \mid z_t) = q$ and $f^{(1)}(\ell_t = \emptyset \mid z_t) = 1-q$.

In the theorem below, we show that the parameter estimates themselves do not change if the probability of observing a label depends \textit{only} on the observation $z_t$ and not the underlying state $X_t$.

\begin{theorem}

    The maximum likelihood estimate and observed fisher information for both models are equal.

\end{theorem}

I argue that this formulation may miss important information if the probability of observing a label is a function of $X_t$ and/or $Y_t$. By explicitly modelling the probability of getting a label from an observation, we treat the presence or absence of a label itself as important information that can be used to model animal movement more accurately.

\subsubsection{weighted labels}

One issue with semi-supervised learning in general occurs when the model used for inference is misspecified data is sparsely labelled. In this case, the likelihood can be dominated by the unlabelled data so that the labelled data will not meaningfully affect maximum likelihood estimates \citep{Chapelle:2006,Ren:2020}. One solution described by \citet{Chapelle:2006} is to use a weighted likelihood that gives separate weight to the labelled and unlabelled data sets. Suppose that there are a total of $n$ labelled observations and $m$ unlabelled observations. Then, the weighted log-density of $\Ya_t$ proposed by \citet{Chapelle:2006} is:

\begin{equation}
    \log\left(\fa^{(i)}(\ya_t)\right) = \left(\frac{m+n}{m}(1-\ell_t)(1-\lambda) + \frac{m+n}{n}\ell_t\lambda\right)  \log\left(f^{(i)}(y_t)\right) + \log \left(f^{(i)}(x_t \ell_t|y_t)\right)
    \label{eqn:w_like}
\end{equation}

where $\lambda \in [0,1]$ represents the relative weight given to labelled observations. Setting $\lambda = 0$ throws out all labelled data, setting $\lambda = 1$ throws out all unlabelled data, and setting $\lambda = n/(n+m)$ returns the standard density of from Equation (\ref{eqn:PHMM_emis}). \citet{Chapelle:2006} mention that $\lambda$ can be tuned via cross validation, but cross validation is ``bound to fail if $n$ is very small". The authors then suggest to set $\lambda = 1$ (i.e. only consider labelled observations), and then slowly decrease $\lambda$ until the likelihood surface exhibits significant multi-modality. I will experiment with both cross-validation as well as the method described by \citet{Chapelle:2006} to tune $\lambda$.